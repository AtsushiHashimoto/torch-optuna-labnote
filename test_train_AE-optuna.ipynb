{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import save_image\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(\"logger\")    #logger名loggerを取得\n",
    "\n",
    "#handler1を作成\n",
    "handler = logging.StreamHandler()\n",
    "handler.setFormatter(logging.Formatter(\"%(asctime)s %(levelname)s %(message)s\"))\n",
    "handler.setLevel(logging.DEBUG) \n",
    "logger.addHandler(handler)\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "import os\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/pyenv/versions/3.6.5/lib/python3.6/site-packages/labnote/core.py:71: UserWarning:\n",
      "\n",
      "Please set your script file name to 'script_name'.\n",
      "\n",
      "/opt/pyenv/versions/3.6.5/lib/python3.6/site-packages/labnote/core.py:72: UserWarning:\n",
      "\n",
      "ex) note.script_name = xxx.ipynb\n",
      "\n",
      "/opt/pyenv/versions/3.6.5/lib/python3.6/site-packages/labnote/core.py:73: UserWarning:\n",
      "\n",
      "NOTE: This warning may happen if you are using jupyter in a docker, and access via port-forwarding. Using jupyter with password authentification can be another possibility.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import labnote as lb\n",
    "if lb.utils.is_executed_on_ipython():\n",
    "    %reload_ext autoreload\n",
    "    %autoreload 2\n",
    "\n",
    "note = lb.Note(arguments=['conf_train_args.yaml',{'config':'conf_AE_optuna.yaml'}])\n",
    "\n",
    "# Fix seed\n",
    "seed = None\n",
    "if 'seed' in note.params.keys():\n",
    "    seed = note.params.seed\n",
    "    np.random.seed(note.params.seed)\n",
    "    _ = torch.manual_seed(note.params.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mnist digits dataset\n",
    "train_data = MNIST(\n",
    "    root='./data/mnist/',\n",
    "    train=True,                                     # this is training data\n",
    "    transform=transforms.ToTensor(),    # Converts a PIL.Image or numpy.ndarray to\n",
    "                                                    # torch.FloatTensor of shape (C x H x W) and normalize in the range [0.0, 1.0]\n",
    "    download=True,                        # download it if you don't have it\n",
    ")\n",
    "# plot one example\n",
    "print(train_data.train_data.size())     # (60000, 28, 28)\n",
    "print(train_data.train_labels.size())   # (60000)\n",
    "plt.imshow(train_data.train_data[2].numpy(), cmap='gray')\n",
    "plt.title('%i' % train_data.train_labels[2])\n",
    "plt.show()\n",
    "\n",
    "# Data Loader for easy mini-batch return in training, the image batch shape will be (50, 1, 28, 28)\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=note.params.batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.network as net\n",
    "import src.utils as my\n",
    "from sys import stdout\n",
    "\n",
    "def to_gpu(x):\n",
    "    gpu = 0\n",
    "    if note.params.gpu<-1:\n",
    "        return x\n",
    "    if note.params.gpu==-1:\n",
    "        gpu = 0\n",
    "    else:\n",
    "        gpu = note.params.gpu\n",
    "    return x.cuda(gpu)\n",
    "def to_cpu(x):\n",
    "    if note.params.gpu<-1:\n",
    "        return x\n",
    "    return x.cpu()\n",
    "\n",
    "try:\n",
    "    writer.close()\n",
    "    my.reset_tensorboard(note.params.output)\n",
    "except:\n",
    "    pass\n",
    "from tensorboardX import SummaryWriter\n",
    "writer = SummaryWriter(note.params.output)\n",
    "\n",
    "def objective(trial): \n",
    "    AE = net.AutoEncoder(note.params,logger,input_dim=1, gpu=note.params.gpu,trial=trial)\n",
    "\n",
    "    optimizer = eval(note.params.optimizer.format('AE',note.params.learning_rate))\n",
    "    epoch = 0\n",
    "    global_step = 0\n",
    "    AE.train()\n",
    "    \n",
    "    print('test params')\n",
    "    for key, value in trial.params.items():\n",
    "        print('    {}: {}'.format(key, value))    \n",
    "    model_path = os.path.join(note.params.output,'model_Trial%02d_'%(trial.trial_id))\n",
    "    \n",
    "    for epoch in range(0,note.params.num_epochs):\n",
    "        for batch_idx, (x,y) in enumerate(train_loader):\n",
    "            x_true = to_gpu(x)\n",
    "            x = to_gpu(2*x-1)\n",
    "            y = to_gpu(y)\n",
    "            optimizer.zero_grad()\n",
    "            z,x_pred = AE.forward(x)\n",
    "            # z = z.detach() # to use z for further calculation.        \n",
    "\n",
    "            # calc reconstruction loss\n",
    "            l = AE.calc_loss('reconstruction',global_step,x_pred,x_true, writer=writer)\n",
    "            l.backward()\n",
    "\n",
    "\n",
    "            optimizer.step()\n",
    "            if batch_idx % 100 == 0:\n",
    "                x_show = np.hstack([to_cpu(x_true[0]).detach(),to_cpu(x_pred[0]).detach()])\n",
    "                writer.add_image('x_pred_epoch%03d'%epoch, x_show, global_step)\n",
    "\n",
    "                trial.report(to_cpu(l.detach()), global_step)\n",
    "                \n",
    "                # Handle pruning based on the intermediate value.\n",
    "                if trial.should_prune(epoch):\n",
    "                    AE.remove(model_path,epoch-1)\n",
    "                    raise optuna.structs.TrialPruned()\n",
    "\n",
    "            loss_data = to_cpu(l.detach()).numpy()\n",
    "            stdout.write(\n",
    "                'Train Epoch: {}/{} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\r'.\n",
    "                format(epoch, note.params.num_epochs, batch_idx * len(x), len(train_loader.dataset),\n",
    "                       100. * batch_idx / len(train_loader), loss_data))        \n",
    "            global_step += 1\n",
    "\n",
    "                \n",
    "            \n",
    "        AE.save(model_path,epoch)\n",
    "    AE.remove(model_path,epoch)\n",
    "    AE.save(model_path)\n",
    "    print(to_cpu(l.detach()).numpy())\n",
    "    return to_cpu(l.detach()).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test params\n",
      "    conv01: 3\n",
      "    conv02: 3\n",
      "    conv03: 13\n",
      "    AE_depth: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/pyenv/versions/3.6.5/lib/python3.6/site-packages/torch/nn/modules/upsampling.py:129: UserWarning:\n",
      "\n",
      "nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06535339h: 2/3 [44928/60000 (100%)]\tLoss: 0.065353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-01-24 19:16:08,035] Finished a trial resulted in value: 0.0653533935546875. Current best value is 0.0653533935546875 with parameters: {'conv01': 3, 'conv02': 3, 'conv03': 13, 'AE_depth': 4}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test params\n",
      "    conv01: 2\n",
      "    conv02: 3\n",
      "    conv03: 9\n",
      "    AE_depth: 2\n",
      "0.06900515h: 2/3 [44928/60000 (100%)]\tLoss: 0.069005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-01-24 19:16:42,688] Finished a trial resulted in value: 0.06900514662265778. Current best value is 0.0653533935546875 with parameters: {'conv01': 3, 'conv02': 3, 'conv03': 13, 'AE_depth': 4}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test params\n",
      "    conv01: 1\n",
      "    conv02: 4\n",
      "    conv03: 16\n",
      "    AE_depth: 4\n",
      "0.06414326h: 2/3 [44928/60000 (100%)]\tLoss: 0.064143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-01-24 19:17:16,502] Finished a trial resulted in value: 0.06414326280355453. Current best value is 0.06414326280355453 with parameters: {'conv01': 1, 'conv02': 4, 'conv03': 16, 'AE_depth': 4}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test params\n",
      "    conv01: 4\n",
      "    conv02: 7\n",
      "    conv03: 9\n",
      "    AE_depth: 2\n",
      "0.06670266h: 2/3 [44928/60000 (100%)]\tLoss: 0.066703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-01-24 19:17:57,574] Finished a trial resulted in value: 0.06670265644788742. Current best value is 0.06414326280355453 with parameters: {'conv01': 1, 'conv02': 4, 'conv03': 16, 'AE_depth': 4}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test params\n",
      "    conv01: 2\n",
      "    conv02: 2\n",
      "    conv03: 15\n",
      "    AE_depth: 4\n",
      "0.061998647: 2/3 [44928/60000 (100%)]\tLoss: 0.061999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-01-24 19:18:30,613] Finished a trial resulted in value: 0.0619986467063427. Current best value is 0.0619986467063427 with parameters: {'conv01': 2, 'conv02': 2, 'conv03': 15, 'AE_depth': 4}.\n"
     ]
    }
   ],
   "source": [
    "# reset tensorboard\n",
    "# netのlayer対応拡張\n",
    "# AE.calc_loss_all\n",
    "study = optuna.create_study()#pruner=optuna.pruners.SuccessiveHalvingPruner())\n",
    "study.optimize(objective,n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  5\n",
      "  Number of pruned trials:  0\n",
      "  Number of complete trials:  5\n",
      "Best trial: 004\n",
      "  Value:  0.0619986467063427\n",
      "  Params: \n",
      "    conv01: 2\n",
      "    conv02: 2\n",
      "    conv03: 15\n",
      "    AE_depth: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "dict expected at most 1 arguments, got 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-354314085170>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualization\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_intermediate_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mplot_intermediate_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/pyenv/versions/3.6.5/lib/python3.6/site-packages/optuna/visualization.py\u001b[0m in \u001b[0;36mplot_intermediate_values\u001b[0;34m(study)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0minit_notebook_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mlayout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshowlegend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0miplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_intermediate_values_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/pyenv/versions/3.6.5/lib/python3.6/site-packages/plotly/graph_objs/graph_objs.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1176\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'data'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_parent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_parent_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/pyenv/versions/3.6.5/lib/python3.6/site-packages/plotly/graph_objs/graph_objs.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0;31m# force key-value pairs to go through validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_raise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_raise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: dict expected at most 1 arguments, got 2"
     ]
    }
   ],
   "source": [
    "pruned_trials = [t for t in study.trials if t.state == optuna.structs.TrialState.PRUNED]\n",
    "complete_trials = [t for t in study.trials if t.state == optuna.structs.TrialState.COMPLETE]\n",
    "\n",
    "print('Study statistics: ')\n",
    "print('  Number of finished trials: ', len(study.trials))\n",
    "print('  Number of pruned trials: ', len(pruned_trials))\n",
    "print('  Number of complete trials: ', len(complete_trials))\n",
    "\n",
    "print('Best trial: %03d'%study.best_trial.trial_id)\n",
    "trial = study.best_trial\n",
    "\n",
    "print('  Value: ', trial.value)\n",
    "\n",
    "print('  Params: ')\n",
    "for key, value in trial.params.items():\n",
    "    print('    {}: {}'.format(key, value))\n",
    "    \n",
    "from optuna.visualization import plot_intermediate_values\n",
    "\n",
    "plot_intermediate_values(study)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
