# conv, maxpool, avgpool, upsample, trans_conv, fc
conv01: trial.suggest_int('conv01', 1, 4) * 8
conv02: trial.suggest_int('conv02', 1, 8) * 8
conv03: trial.suggest_int('conv03', 1, 16) * 8

encoder: [
  ['conv', conv01 ,3,1,1,'bn','LeakyReLU'],
  ['avgpool',2],
  ['conv', conv02 ,3,1,1,'bn','LeakyReLU'],
  ['avgpool',2],
  ['conv', conv03 ,3,1,1,'bn'],
    ]
    
AE_depth: trial.suggest_int('AE_depth', 1, 5)

decoder: [
  ['conv', conv02 ,3,1,1,'bn','LeakyReLU'],
  ['upsample',2],
  ['conv', conv01 ,3,1,1,'bn','LeakyReLU'],
  ['upsample',2],
  ['conv', 1,3,1,1,'bn','Softplus'],
]

initialize:
  Conv: '{}.data.normal_(0.0, 0.1)'
  BatchNorm: [
    '{}.data.uniform_()',
    '{}.bias.data.zero_()'
  ]

optimizer: "torch.optim.Adam(list({}.parameters()), lr={},betas=(0.5,0.999))"

losses:
  reconstruction:
    lambda: 1.0 # or [0.0, 1.0, 0, 50000] -> at start, 0.0, and at 50000 steps, 1.0.
    func: torch.nn.MSELoss()